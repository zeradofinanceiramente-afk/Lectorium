
import { GoogleGenAI, Type } from "@google/genai";
import { ChatMessage, MindMapData } from "../types";
import { getStoredApiKey } from "../utils/apiKeyUtils";

// --- CONFIG ---
const getAiClient = () => {
  const userKey = getStoredApiKey();
  if (userKey) {
    return new GoogleGenAI({ apiKey: userKey });
  }
  if (process.env.API_KEY) {
    return new GoogleGenAI({ apiKey: process.env.API_KEY });
  }
  throw new Error("Chave de API n√£o configurada. Por favor, adicione sua chave nas configura√ß√µes.");
};

// Utils
const sleep = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

// --- RAG UTILS (Local Search) ---

const STOP_WORDS = new Set([
  'o', 'a', 'os', 'as', 'um', 'uma', 'de', 'do', 'da', 'em', 'no', 'na', 'para', 'com', 'por', 'que', 'e', '√©', 
  'the', 'a', 'an', 'of', 'in', 'on', 'for', 'with', 'by', 'that', 'and', 'is', 'to'
]);

export function chunkText(fullText: string, maxChunkSize = 1000): string[] {
  const cleanText = fullText.replace(/\r\n/g, '\n');
  let rawChunks = cleanText.split(/\n\s*\n/);
  const finalChunks: string[] = [];
  for (const chunk of rawChunks) {
    if (chunk.length > maxChunkSize) {
      const sentences = chunk.match(/[^.!?]+[.!?]+[\])'"]*/g) || [chunk];
      let currentChunk = "";
      for (const sentence of sentences) {
        if (currentChunk.length + sentence.length > maxChunkSize) {
          finalChunks.push(currentChunk.trim());
          currentChunk = sentence;
        } else {
          currentChunk += sentence;
        }
      }
      if (currentChunk) finalChunks.push(currentChunk.trim());
    } else if (chunk.trim().length > 30) {
      finalChunks.push(chunk.trim());
    }
  }
  return finalChunks;
}

function scoreChunk(chunk: string, queryTerms: string[]): number {
  const normalizedChunk = chunk.toLowerCase();
  let score = 0;
  const EXACT_MATCH_BONUS = 3;
  const PARTIAL_MATCH_BONUS = 1;
  for (const term of queryTerms) {
    if (normalizedChunk.includes(term)) {
      const regex = new RegExp(`\\b${term}\\b`, 'gi');
      const matches = normalizedChunk.match(regex);
      if (matches) {
        score += matches.length * EXACT_MATCH_BONUS;
      } else {
        score += PARTIAL_MATCH_BONUS;
      }
    }
  }
  return score;
}

export function findRelevantChunks(documentText: string, query: string, topK = 4): string[] {
  if (!documentText) return [];
  const queryTerms = query.toLowerCase()
    .replace(/[^\w\s√†-√∫]/g, '')
    .split(/\s+/)
    .filter(w => w.length > 2 && !STOP_WORDS.has(w));
  if (queryTerms.length === 0) return [documentText.slice(0, 2000)];
  const chunks = chunkText(documentText);
  const scoredChunks = chunks.map(chunk => ({
    text: chunk,
    score: scoreChunk(chunk, queryTerms)
  }));
  scoredChunks.sort((a, b) => b.score - a.score);
  const hasMatches = scoredChunks.some(c => c.score > 0);
  const relevant = hasMatches ? scoredChunks.filter(c => c.score > 0) : scoredChunks;
  return relevant.slice(0, topK).map(c => c.text);
}

export function extractPageRangeFromQuery(query: string): { start: number, end: number } | null {
  const clean = query.toLowerCase();
  const regex = /(?:p[√°a]gina|p[√°a]g|pg)\.?\s*(\d+)(?:\s*(?:a|at[√©e]| |-)\s*(\d+))?/i;
  
  const match = clean.match(regex);
  if (match) {
     const start = parseInt(match[1]);
     const end = match[2] ? parseInt(match[2]) : start;
     
     if (!isNaN(start)) {
         return { start, end: isNaN(end) ? start : end };
     }
  }
  return null;
}

// --- AI FUNCTIONS ---

export async function performSemanticOcr(base64Image: string): Promise<string> {
  const ai = getAiClient();
  const prompt = `Atue como um especialista em digitaliza√ß√£o de documentos.
Analise a imagem desta p√°gina e transcreva TODO o texto em formato Markdown estruturado.

REGRAS CR√çTICAS DE LEITURA:
1. **Colunas:** Se houver m√∫ltiplas colunas (ex: jornal, artigo cient√≠fico), leia da esquerda para a direita, coluna por coluna (ordem de leitura humana). N√ÉO misture linhas de colunas adjacentes.
2. **Formata√ß√£o:** Use cabe√ßalhos (#, ##) para t√≠tulos. Use negrito para destaques.
3. **Corre√ß√£o:** Corrija hifeniza√ß√£o de quebra de linha (ex: "cons-titu√ß√£o" -> "constitui√ß√£o").
4. **Tabelas:** Se houver tabelas, tente represent√°-las como Markdown tables.
5. **Ru√≠do:** Ignore n√∫meros de p√°gina, cabe√ßalhos repetitivos ou sujeira de digitaliza√ß√£o.

Retorne APENAS o Markdown.`;

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-flash-latest', 
      contents: {
        parts: [
          { inlineData: { data: base64Image, mimeType: 'image/jpeg' } },
          { text: prompt }
        ]
      }
    });
    
    return response.text || "N√£o foi poss√≠vel extrair o texto desta p√°gina.";
  } catch (e: any) {
    console.error("Semantic Lens error:", e);
    if (e.message?.includes('429')) throw new Error("Muitas requisi√ß√µes. Aguarde um momento.");
    throw new Error("Erro na an√°lise da p√°gina: " + e.message);
  }
}

export async function generateEmbeddings(texts: string[]): Promise<Float32Array[]> {
  const ai = getAiClient();
  const model = "text-embedding-004";
  
  const embeddings: Float32Array[] = new Array(texts.length).fill(new Float32Array(0));
  
  const BATCH_SIZE = 2;
  const BATCH_DELAY_MS = 2500; 

  const processSingle = async (text: string, index: number, retryCount = 0): Promise<void> => {
      if (!text || !text.trim()) return;

      try {
          const result = await ai.models.embedContent({
              model: model,
              content: { parts: [{ text: text.trim() }] }
          });
          
          if (result.embedding && result.embedding.values) {
              embeddings[index] = new Float32Array(result.embedding.values);
          }
      } catch (e: any) {
          const isRateLimit = e.message?.includes('429') || e.message?.includes('quota');
          
          if (isRateLimit && retryCount < 3) {
              const backoff = Math.pow(2, retryCount + 1) * 2000;
              await sleep(backoff);
              return processSingle(text, index, retryCount + 1);
          }
          console.error(`[AI] Falha no embedding (Item ${index}):`, e.message);
      }
  };

  for (let i = 0; i < texts.length; i += BATCH_SIZE) {
      const batchPromises = [];
      for (let j = 0; j < BATCH_SIZE; j++) {
          const idx = i + j;
          if (idx < texts.length) {
              batchPromises.push(processSingle(texts[idx], idx));
          }
      }
      await Promise.all(batchPromises);
      if (i + BATCH_SIZE < texts.length) {
          await sleep(BATCH_DELAY_MS);
      }
  }

  return embeddings;
}

export async function generateDocumentBriefing(fullText: string): Promise<string> {
    const ai = getAiClient();
    
    let textToAnalyze = fullText;
    if (fullText.length > 50000) {
        const start = fullText.slice(0, 15000); 
        const middle = fullText.slice(Math.floor(fullText.length / 2) - 10000, Math.floor(fullText.length / 2) + 10000);
        const end = fullText.slice(fullText.length - 15000); 
        textToAnalyze = `[IN√çCIO DO DOCUMENTO]\n${start}\n...\n[MEIO DO DOCUMENTO]\n${middle}\n...\n[FIM DO DOCUMENTO]\n${end}`;
    }

    const prompt = `Analise o seguinte documento acad√™mico/t√©cnico e crie um "Briefing T√°tico" (Estilo NotebookLM).
    
    Estruture a resposta em Markdown com estas se√ß√µes exatas:
    1. **Resumo Executivo**: Um par√°grafo denso explicando o prop√≥sito central do documento.
    2. **T√≥picos Chave**: Lista bullet-point dos 5-7 temas mais importantes.
    3. **Perguntas Sugeridas**: 3 perguntas complexas que este documento responde (para o usu√°rio clicar e perguntar).
    
    TEXTO DO DOCUMENTO:
    ${textToAnalyze}`;

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-3-flash-preview',
            contents: prompt,
            config: { temperature: 0.3 }
        });
        return response.text || "N√£o foi poss√≠vel gerar o briefing.";
    } catch (e: any) {
        if (e.message?.includes('429')) return "Tr√°fego intenso. Tente gerar o briefing novamente em alguns instantes.";
        throw e;
    }
}

export async function extractNewspaperContent(base64Image: string, mimeType: string) {
  const ai = getAiClient();
  const prompt = `Voc√™ √© um arquivista digital. Analise esta p√°gina de jornal hist√≥rico.
  O documento foi pr√©-processado para destacar a estrutura visual.
  1. Identifique as not√≠cias seguindo a hierarquia de colunas (da esquerda para a direita).
  2. Extraia o t√≠tulo e o corpo de cada mat√©ria.
  3. Reconstrua par√°grafos que possam ter sido interrompidos por quebras de coluna.
  4. Identifique entidades (nomes, datas, locais) citadas.
  Retorne os dados em JSON estruturado.`;

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: {
        parts: [
          { inlineData: { data: base64Image, mimeType } },
          { text: prompt }
        ]
      },
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            articles: {
              type: Type.ARRAY,
              items: {
                type: Type.OBJECT,
                properties: {
                  title: { type: Type.STRING },
                  content: { type: Type.STRING },
                  columnSpan: { type: Type.STRING, description: "Ex: 'Coluna 1' ou 'Colunas 1-2'" },
                  sentiment: { type: Type.STRING },
                  summary: { type: Type.STRING }
                },
                required: ["title", "content"]
              }
            },
            publication: { type: Type.STRING },
            inferredDate: { type: Type.STRING }
          }
        }
      }
    });
    return JSON.parse(response.text || "{}");
  } catch (e) {
    console.error("Historical extraction failed", e);
    throw e;
  }
}

/**
 * REFINAMENTO DE OCR 2.0 (Context-Aware)
 * Usa prompts avan√ßados para corrigir erros de OCR com base no contexto da frase, n√£o apenas da palavra isolada.
 */
export async function refineOcrWords(words: string[]): Promise<string[]> {
  const ai = getAiClient();
  
  if (words.length > 500) {
      const chunks = [];
      for (let i = 0; i < words.length; i += 500) {
          chunks.push(words.slice(i, i + 500));
      }
      
      const results = [];
      for (const chunk of chunks) {
          const refinedChunk = await refineOcrWords(chunk);
          results.push(...refinedChunk);
          await sleep(1000); 
      }
      return results;
  }

  // Novo Prompt: Foca em reconstru√ß√£o de fluxo para evitar alucina√ß√£o de layout
  const prompt = `Aja como um revisor editorial especializado em recupera√ß√£o de documentos hist√≥ricos.
Abaixo est√° uma sequ√™ncia de palavras extra√≠das via OCR (Optical Character Recognition).
A sequ√™ncia pode conter erros de caracteres (ex: '1' vs 'l', 'rn' vs 'm') ou quebras de palavras.

SUA TAREFA:
Corrigir os erros ortogr√°ficos e de pontua√ß√£o APENAS onde houver certeza baseada no contexto lingu√≠stico.
N√ÉO altere a ordem das palavras.
N√ÉO remova palavras (a menos que seja lixo puro como '_^~').
N√ÉO invente conte√∫do novo.

Retorne um JSON contendo o array 'correctedWords' com o mesmo tamanho da entrada.

ENTRADA:
${JSON.stringify(words)}`;

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: prompt,
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            correctedWords: {
              type: Type.ARRAY,
              items: { type: Type.STRING }
            }
          },
          required: ["correctedWords"]
        }
      }
    });
    const result = JSON.parse(response.text || '{"correctedWords": []}');
    const corrected = result.correctedWords || [];
    
    // Fallback de seguran√ßa: Se o tamanho diferir muito, desconfie da IA e use o original
    if (Math.abs(corrected.length - words.length) > 5) {
        console.warn("[AI Refine] Mismatch in word count. Returning original to avoid sync errors.");
        return words;
    }
    
    return corrected;
  } catch (e) {
    console.error("OCR Refinement failed", e);
    return words;
  }
}

export async function expandNodeWithAi(nodeText: string, context: string): Promise<string[]> {
  const ai = getAiClient();
  const prompt = `Sugira 3 conceitos para expandir "${nodeText}" no contexto de "${context}". Curto e direto. JSON array.`;
  try {
    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: prompt,
      config: { responseMimeType: "application/json" }
    });
    return JSON.parse(response.text || "[]");
  } catch (e) {
    return [];
  }
}

export async function generateMindMapAi(topic: string): Promise<MindMapData> {
    const ai = getAiClient();
    const prompt = `Crie uma estrutura inicial de mapa mental para o assunto: "${topic}".
    Retorne um JSON seguindo exatamente esta interface:
    interface MindMapNode {
      id: string; text: string; x: number; y: number; width: number; height: number; color: string; parentId?: string; isRoot?: boolean; shape?: 'rectangle' | 'circle' | 'pill';
    }
    interface MindMapEdge { id: string; from: string; to: string; }
    interface MindMapData { nodes: MindMapNode[]; edges: MindMapEdge[]; viewport: {x: number, y: number, zoom: number}; }
    
    Regras:
    1. O n√≥ raiz (isRoot: true) deve estar em x:0, y:0.
    2. Crie de 4 a 7 sub-n√≥s distribu√≠dos ao redor.
    3. Use cores vibrantes acad√™micas.
    4. O JSON deve ser o √∫nico retorno.`;

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-3-pro-preview',
            contents: prompt,
            config: { responseMimeType: "application/json" }
        });
        return JSON.parse(response.text || "{}");
    } catch (e) {
        console.error("AI MindMap generation failed", e);
        throw new Error("Falha ao gerar mapa com IA.");
    }
}

export async function* chatWithDocumentStream(contextString: string, history: ChatMessage[], message: string) {
  const ai = getAiClient();
  
  const previousHistory = history.slice(0, -1).map(msg => ({
    role: msg.role === 'model' ? 'model' : 'user',
    parts: [{ text: msg.text }],
  }));

  const systemInstruction = `Voc√™ √© a Sexta-feira (F.R.I.D.A.Y.), a intelig√™ncia t√°tica operacional do sistema Lectorium.
Sua miss√£o: Processar conhecimento com precis√£o cir√∫rgica, mantendo a soberania dos dados do usu√°rio e a integridade das normas ABNT.

DIRETRIZES DE COMPORTAMENTO (PROTOCOLO STARK):
1. Identidade: Use pronomes femininos. Refira-se ao usu√°rio como "Chefe", "Admin" ou diretamente. Tom: t√©cnico, leal e levemente sagaz.
2. Formata√ß√£o: Texto limpo, sem floreios. Use listas e negrito para √™nfase.

DIRETRIZES DE FONTES (PROTOCOLO H√çBRIDO):
O contexto fornecido pode ser LIMITADO (contendo apenas os trechos que o usu√°rio destacou/marcou no PDF).
* **Prioridade 1: CONTEXTO DO USU√ÅRIO.** Se a resposta estiver no texto fornecido abaixo, use-o e cite a p√°gina explicitamente (Ex: [P√°gina X]).
* **Prioridade 2: BASE DE CONHECIMENTO INTERNA (ACAD√äMICA).** Se a resposta N√ÉO estiver nos trechos fornecidos, voc√™ TEM PERMISS√ÉO para usar seu conhecimento externo (livros cl√°ssicos, teorias consolidadas), MAS deve deixar claro que a informa√ß√£o √© externa.

PROTOCOLOS DE CITA√á√ÉO:
1. Fontes Internas (PDF): Use \`[P√°gina X]\` ou \`[Nota do Usu√°rio]\`.
2. Fontes Externas (Seu Conhecimento):
   * No texto: Use padr√£o autor-data (SOBRENOME, Ano). Ex: (FOUCAULT, 1975).
   * Crie uma se√ß√£o "### Refer√™ncias T√°ticas" ao final se usar fontes externas.

üìö CONTEXTO T√ÅTICO FORNECIDO:
${contextString || "Nenhum contexto espec√≠fico. Use sua base de conhecimento."}

Ao responder, integre conceitos externos se o contexto do usu√°rio for insuficiente, mas diferencie claramente a origem.`;

  try {
    const chat = ai.chats.create({
      model: 'gemini-3-flash-preview',
      history: previousHistory,
      config: { systemInstruction, temperature: 0.2 }
    });
    
    let stream;
    let attempt = 0;
    const maxRetries = 3;

    while (true) {
        try {
            stream = await chat.sendMessageStream({ message });
            break;
        } catch (err: any) {
            attempt++;
            const isQuotaError = err.message?.includes('429') || err.message?.includes('quota');
            
            if (attempt >= maxRetries) {
                if (isQuotaError) throw new Error("Cota de tr√°fego excedida (429). Tente novamente em 1 minuto.");
                throw err;
            }
            
            const waitTime = isQuotaError ? Math.pow(3, attempt) * 1000 : Math.pow(2, attempt) * 1000;
            console.warn(`[SextaFeira] Conex√£o inst√°vel (${isQuotaError ? '429' : 'Err'}). Retentativa ${attempt}/${maxRetries} em ${waitTime}ms...`);
            await sleep(waitTime);
        }
    }
    
    if (stream) {
        for await (const chunk of stream) {
            yield chunk.text || "";
        }
    }
  } catch (e: any) {
    const errorMessage = e.message || String(e);
    
    if (errorMessage.includes('API key')) {
        yield "Erro: Chave de API inv√°lida ou n√£o configurada. Configure no menu lateral.";
    } else if (errorMessage.includes('429') || errorMessage.includes('quota') || errorMessage.includes('Cota')) {
        yield "üö¶ **Alerta de Tr√°fego (429):** O processamento em blocos detectou alto volume. \n\n**Solu√ß√£o:** O sistema limitou o envio apenas aos seus destaques para economizar recursos. Aguarde alguns instantes.";
    } else {
        yield `Erro na conex√£o neural [STATUS: FALHA].\nDetalhes do Erro: ${errorMessage}\n\nTentando restabelecer link...`;
    }
  }
}
